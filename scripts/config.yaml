cluster_name: tali-cluster

project: <project id>
zone: us-central1-f

external_compute_ips: false
google_app_cred_path: /shared/slurm/scripts/service_account.key

shared_vpc_host_project: tali-multi-modal
vpc_subnet: tali-cluster-network

slurm_cmd_path: /usr/local/bin
log_dir: /var/log/slurm

compute_node_scopes:
- https://www.googleapis.com/auth/monitoring.write
- https://www.googleapis.com/auth/logging.write
- https://www.googleapis.com/auth/cloud-platform
compute_node_service_account: tali-multi-modal@tali-multi-modal.iam.gserviceaccount.com

update_node_addrs: true

network_storage: []
login_network_storage: []

instance_defs:
  worker-small:
    machine_type: n1-standard-2
    zone: us-west1-b
    image: projects/schedmd-slurm-public/global/images/family/schedmd-slurm-21-08-4-debian-10
    image_hyperthreads: true
    compute_disk_size_gb: 350
    compute_disk_type: pd-standard
    compute_labels: {}
    cpu_platform: null
    gpu_count: 1
    gpu_type: nvidia-tesla-a100
    enable_placement: false
    exclusive: false
    instance_template: projects/tali-multi-modal/global/instanceTemplates/gpu-small-node
    network_storage: []
    preemptible_bursting: true
    regional_capacity: false
    regional_policy: {}
    vpc_subnet: tali-cluster-network
    compute_node_service_account: tali-multi-modal@tali-multi-modal.iam.gserviceaccount.com
    compute_node_scopes: ["https://www.googleapis.com/auth/cloud-platform"]

#partitions = [
#
#  { name                 = "worker-small"
#    machine_type         = "a2-highgpu-1g"
#    static_node_count    = 4
#    max_node_count       = 20
#    zone                 = "us-central1-f"
#    image                = "projects/schedmd-slurm-public/global/images/family/schedmd-slurm-21-08-4-debian-10"
#    image_hyperthreads   = true
#    cpu_platform         = null
#    compute_disk_type    = "pd-standard"
#    compute_disk_size_gb = 350
#    compute_labels       = {}
#    regional_capacity    = false
#    regional_policy      = {}
#    gpu_count            = 1
#    gpu_type             = "nvidia-tesla-a100"
#    network_storage      = []
#    preemptible_bursting = "spot"
#    vpc_subnet           = null
#    exclusive            = false
#    enable_placement     = false
#    regional_capacity    = false
#    regional_policy      = {}
#    instance_template    = "projects/tali-multi-modal/global/instanceTemplates/gpu-small-node"
#    compute_node_service_account = "tali-multi-modal@tali-multi-modal.iam.gserviceaccount.com"
#    compute_node_scopes          = [
#     "https://www.googleapis.com/auth/cloud-platform"
#    ]

#    compute_startup_script = <<-EOT
#    #!/bin/bash
#    export MOUNT_DIR="/mnt/disk/filestore/"
#    export EXPERIMENTS_DIR="/mnt/disk/filestore/experiments/"
#
#    if [ ! -d "$MOUNT_DIR" ]; then
#      sudo mkdir -p $MOUNT_DIR
#      sudo chmod -Rv 777 $MOUNT_DIR
#    fi
#
#    if [ ! -d "$EXPERIMENTS_DIR" ]; then
#      sudo mkdir -p $EXPERIMENTS_DIR
#      sudo chmod -Rv 777 $EXPERIMENTS_DIR
#    fi
#    ########################################################################################
#    export DATASET_DIR="/mnt/disk/filestore/tali-dataset/"
#
#    if [ ! -d "$DATASET_DIR" ]; then
#      sudo mkdir -p $DATASET_DIR
#      sudo chmod -Rv 777 $DATASET_DIR
#    fi
#
#    sudo mount -o discard,defaults /dev/sdb $DATASET_DIR
#
#    #sudo chmod -Rv 777 $DATASET_DIR
#    ########################################################################################
#    EOT

    # With regional_capacity : true, the region can be specified in the zone.
    # Otherwise the region will be inferred from the zone.


    # When specifying an instance template, specified compute fields will
    # override the template properties
  }
]